{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99fcdf0a73f3d615",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/hdakhli/mlops-2024/blob/main/20_neural_net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9879c03ec87473a1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Classifier des images\n",
    "\n",
    "Suivre les étapes indiquées dans le notebook pour classifier des images de chiffres manuscrits en utilisant un réseau de neurones.\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"datasets/MNIST-dataset.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6db20d9ed387ff9d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.26.2)\n",
      "Requirement already satisfied: tensorflow in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.12.0)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (3.8.2)\n",
      "Collecting opencv-python-headless\n",
      "  Downloading opencv_python_headless-4.9.0.80-cp37-abi3-macosx_10_16_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (3.8.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (0.4.11)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (16.0.0)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.23.5-cp311-cp311-macosx_10_9_x86_64.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (4.23.2)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (4.8.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (1.54.2)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (2.12.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (0.32.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jax>=0.3.15->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: scipy>=1.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.4)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n",
      "Downloading numpy-1.23.5-cp311-cp311-macosx_10_9_x86_64.whl (18.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading opencv_python_headless-4.9.0.80-cp37-abi3-macosx_10_16_x86_64.whl (55.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy, opencv-python-headless\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.2\n",
      "    Uninstalling numpy-1.26.2:\n",
      "      Successfully uninstalled numpy-1.26.2\n",
      "Successfully installed numpy-1.23.5 opencv-python-headless-4.9.0.80\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy tensorflow matplotlib opencv-python-headless"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1884d4ea9742c805",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Importer les librairies\n",
    "\n",
    "- Tensorflow is an end-to-end open source platform for machine learning. \n",
    "- Keras is an open-source library that provides a Python interface for artificial neural networks.\n",
    "- numpy is the main package for scientific computing with Python.\n",
    "- matplotlib is a library to plot graphs in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-27 10:55:44.649738: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "np.random.seed(42)\n",
    "from keras.optimizers import Adam, SGD      # help us to transform our data later\n",
    "from tensorflow.python.keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462cf843071f3e30",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Load the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b75fb44896a6d52",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11490434/11490434 [==============================] - 6s 0us/step\n"
     ]
    }
   ],
   "source": [
    "#(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "import ssl\n",
    "import urllib.request\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74522659b698c08",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Checkout input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2911f91cd12af29c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of Images:  60000\n",
      "Size of Image: (28, 28)\n",
      "Total no of labels: (60000,)\n"
     ]
    }
   ],
   "source": [
    "print('Total no of Images: ',X_train.shape[0])\n",
    "print('Size of Image:', X_train.shape[1:])\n",
    "print('Total no of labels:', y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e46d6a32fa3ab6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Prepare input data\n",
    "For a multi-layer perceptron model we must reduce the images down into a vector of pixels. In this case the 28×28 sized images will be 784 pixel input values.\n",
    "\n",
    "We can do this transform easily using the reshape() function on the NumPy array. We can also reduce our memory requirements by forcing the precision of the pixel values to be 32 bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d07b3f47db6185d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape((X_train.shape[0],-1))\n",
    "X_test = X_test.reshape((X_test.shape[0], -1))\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19279233ad0f953",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Normalize Input data\n",
    "The pixel values are gray scale between 0 and 255. It is almost always a good idea to perform some scaling of input values when using neural network models. Because the scale is well known and well behaved, we can very quickly normalize the pixel values to the range 0 and 1 by dividing each value by the maximum of 255.\n",
    "<br>\n",
    "<img src=\"datasets/three_pixels.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4838a4d5ec7ba5b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "\n",
    "# print(X_train[0])\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc26a2c16493dc0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## One-hot Encoding\n",
    "\n",
    "Finally, the output variable is an integer from 0 to 9. This is a multi-class classification problem. As such, it is good practice to use a one hot encoding of the class values, transforming the vector of class integers into a binary matrix.\n",
    "\n",
    "### What is Categorial Data?\n",
    "\n",
    "Categorical data are variables that contain label values rather than numeric values. The number of possible values is often limited to a fixed set. \n",
    "\n",
    "Some examples include:\n",
    "\n",
    "- A “pet” variable with the values: “dog” and “cat“.\n",
    "- A “color” variable with the values: “red“, “green” and “blue“.\n",
    "- A “place” variable with the values: “first”, “second” and “third“.\n",
    "- A \"Number\" variable with values: \"0\", \"1\", \"2\", ... , \"9\".\n",
    "\n",
    "### Convert Categorical Data to Numerical Data.\n",
    "\n",
    "Here, the integer encoded variable is removed and a new binary variable is added for each unique integer value.\n",
    "\n",
    "\n",
    "In the “color” variable example, there are 3 categories and therefore 3 binary variables are needed. A “1” value is placed in the binary variable for the color and “0” values for the other colors.\n",
    "\n",
    "    - red,\t\tgreen,\t\tblue\n",
    "    - 1,\t\t0,\t\t0\n",
    "    - 0,\t\t1,\t\t0\n",
    "    - 0,\t\t0,\t\t1\n",
    "\n",
    "\n",
    "We can easily do this using the built-in **np_utils.to_categorical()** helper function in Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "709f7af8370fb7e0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "150b1dba7b198a0a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_classes = y_test.shape[1]\n",
    "num_pixels = 784"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56883a8aedf8ee51",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Define Model\n",
    "\n",
    "Input size of our model - 784 (28 x 28). There are 2 hidden layers with 256 and 64 neurons in each.\n",
    "In hidden layers, we will use relu activation function. And in final output layer, we'll use softmax activation function.\n",
    "\n",
    "#### Relu Function:\n",
    "The rectified linear activation function or ReLU for short is a piecewise linear function that will output the input directly if it is positive, otherwise, it will output zero.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Softmax Function:\n",
    "The Softmax function that turns numbers aka logits into probabilities that sum to one. Softmax function outputs a vector that represents the probability distributions of a list of potential outcomes.\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"datasets/activation.png\" width=\"1000\">\n",
    "\n",
    "<br>\n",
    "\n",
    "So our final model look like this,\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"datasets/nn_archi.png\" width=\"1000\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa4b54366590691",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define baseline model\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=num_pixels, activation=\"relu\"))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d2b33f19d76494a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               200960    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 218,058\n",
      "Trainable params: 218,058\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765b5b872921251c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Compile Model\n",
    "\n",
    "#### Loss Function: Categorical Crossentropy\n",
    "The categorical crossentropy is well suited to classification tasks, since one example can be considered to belong to a specific category with probability 1, and to other categories with probability 0.\n",
    "\n",
    "<br/>\n",
    "\n",
    "#### Optimizer: SGD (Stochastic Gradient Descent)\n",
    "Stochastic gradient descent is an iterative method for optimizing an objective function with suitable smoothness properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9537a504e2599dd",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opt = SGD(learning_rate=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4b9888b413a6d4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Train Model\n",
    "To fit the model, all we have to do is declare the batch size and number of epochs to train for, then pass in our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a360b3d0dae9c0f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 11s 5ms/step - loss: 1.7253 - accuracy: 0.5628\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.8591 - accuracy: 0.8170\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.5806 - accuracy: 0.8574\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.4764 - accuracy: 0.8759\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.4218 - accuracy: 0.8859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x131f774d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fd862073bd6c5e6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3849 - accuracy: 0.8938\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fec572d4a95002a8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step\n",
      "2\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m P[\u001b[38;5;241m1\u001b[39m][k]\u001b[38;5;241m==\u001b[39mP[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mmax():\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28mprint\u001b[39m(k)\n\u001b[0;32m----> 6\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241m.\u001b[39mfromarray(X_test)\n\u001b[1;32m      7\u001b[0m img\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Tester avec les images présentes dans le dossier \"datasets\"\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Image' is not defined"
     ]
    }
   ],
   "source": [
    "# Faire une prédiction d'une image de test\n",
    "P = model.predict(X_test)\n",
    "for k in range(len(P[1])):\n",
    "    if P[1][k]==P[1].max():\n",
    "        print(k)\n",
    "img = Image.fromarray(X_test)\n",
    "img.show()\n",
    "# Tester avec les images présentes dans le dossier \"datasets\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
